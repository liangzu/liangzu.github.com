<!doctype html>
<html lang="en">
<head>
<title>Paper Reading Notebook</title>
<!-- 2018-01-08 一 10:12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="generator" content="Org-mode">
<meta name="author" content="Liangzu Peng">

<link  href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>
<style type="text/css">
/* org mode styles on top of twbs */

html {
    position: relative;
    min-height: 100%;
}

body {
    font-size: 18px;
    margin-bottom: 105px;
}

footer {
    position: absolute;
    bottom: 0;
    width: 100%;
    height: 101px;
    background-color: #f5f5f5;
}

footer > div {
    padding: 10px;
}

footer p {
    margin: 0 0 5px;
    text-align: center;
    font-size: 16px;
}

#table-of-contents {
    margin-top: 20px;
    margin-bottom: 20px;
}

blockquote p {
    font-size: 18px;
}

pre {
    font-size: 16px;
}

.footpara {
    display: inline-block;
}

figcaption {
  font-size: 16px;
  color: #666;
  font-style: italic;
  padding-bottom: 15px;
}

/* from twbs docs */

.bs-docs-sidebar.affix {
    position: static;
}
@media (min-width: 768px) {
    .bs-docs-sidebar {
        padding-left: 20px;
    }
}

/* All levels of nav */
.bs-docs-sidebar .nav > li > a {
    display: block;
    padding: 4px 20px;
    font-size: 14px;
    font-weight: 500;
    color: #999;
}
.bs-docs-sidebar .nav > li > a:hover,
.bs-docs-sidebar .nav > li > a:focus {
    padding-left: 19px;
    color: #A1283B;
    text-decoration: none;
    background-color: transparent;
    border-left: 1px solid #A1283B;
}
.bs-docs-sidebar .nav > .active > a,
.bs-docs-sidebar .nav > .active:hover > a,
.bs-docs-sidebar .nav > .active:focus > a {
    padding-left: 18px;
    font-weight: bold;
    color: #A1283B;
    background-color: transparent;
    border-left: 2px solid #A1283B;
}

/* Nav: second level (shown on .active) */
.bs-docs-sidebar .nav .nav {
    display: none; /* Hide by default, but at >768px, show it */
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 30px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav > li > a:focus {
    padding-left: 29px;
}
.bs-docs-sidebar .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav > .active:focus > a {
    padding-left: 28px;
    font-weight: 500;
}

/* Nav: third level (shown on .active) */
.bs-docs-sidebar .nav .nav .nav {
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 40px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav .nav > li > a:focus {
    padding-left: 39px;
}
.bs-docs-sidebar .nav .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav .nav > .active:focus > a {
    padding-left: 38px;
    font-weight: 500;
}

/* Show and affix the side nav when space allows it */
@media (min-width: 992px) {
    .bs-docs-sidebar .nav > .active > ul {
        display: block;
    }
    /* Widen the fixed sidebar */
    .bs-docs-sidebar.affix,
    .bs-docs-sidebar.affix-bottom {
        width: 213px;
    }
    .bs-docs-sidebar.affix {
        position: fixed; /* Undo the static from mobile first approach */
        top: 20px;
    }
    .bs-docs-sidebar.affix-bottom {
        position: absolute; /* Undo the static from mobile first approach */
    }
    .bs-docs-sidebar.affix .bs-docs-sidenav,.bs-docs-sidebar.affix-bottom .bs-docs-sidenav {
        margin-top: 0;
        margin-bottom: 0
    }
}
@media (min-width: 1200px) {
    /* Widen the fixed sidebar again */
    .bs-docs-sidebar.affix-bottom,
    .bs-docs-sidebar.affix {
        width: 263px;
    }
}
</style>
<script type="text/javascript">
$(function() {
    'use strict';

    $('.bs-docs-sidebar li').first().addClass('active');

    $(document.body).scrollspy({target: '.bs-docs-sidebar'});

    $('.bs-docs-sidebar').affix();
});
</script>
</head>
<body>
<div id="content" class="container">
<div class="row"><div class="col-md-9"><h1 class="title">Paper Reading Notebook</h1>
<blockquote>
<p>
"<i>The palest ink is better than the best memory.</i>"
</p>

<p>
&#x2014;&#x2014; <i>an old saying</i>
</p>
</blockquote>

<p>
This page is used to share my recent paper reading for
writing-training and "report/lie to advisor" purpose. The
notes are mostly copied from the paper, I will use my own
word to write if the word itself comes to my mind.
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> 2017.6.29-2017.9.10</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Transformation-Grouned Image Generation Network for Novel 3D View Synthesis</h3>
<div class="outline-text-3" id="text-1-1">
</div><div id="outline-container-sec-1-1-1" class="outline-4">
<h4 id="sec-1-1-1"><span class="section-number-4">1.1.1</span> Problem Description(Novel View Synthesis)</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
Given a single view of an object in an arbitrary pose, the goal is to
synthesize an image of the object after a specified transformation of
viewpoint.
</p>

<p>
Novel view synthesis could be seen as a combination of the following
three scenarios:
</p>
<ol class="org-ol">
<li>pixels in the input view that remain visible in the target view are
moved to their corresponding positions,
</li>
<li>remaining pixels in the input view disappear due to occlusions,
</li>
<li>previously unseen pixels are revealed or disoccluded in the target
view.
</li>
</ol>

<p>
This problem is not merely <code>important</code> because it has a variety of practical
applications in vision, graphics and robotics, but also generally
<code>challenging</code> due to unspecified input viewing angle and the ambiguities
of 3D shape observed in only a single view.
</p>
</div>
</div>
<div id="outline-container-sec-1-1-2" class="outline-4">
<h4 id="sec-1-1-2"><span class="section-number-4">1.1.2</span> Solution Description</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
to solve the problem mentioned above, we need to sequentially solve two
sub-problem described as follows:
</p>
<ol class="org-ol">
<li>designing a network to transform the pixels of the input view that
remain visible(<b>DOAFN</b> in the paper).
</li>
<li>designing a network that infers the unseen pixels of the target
view given theses transformed pixels(view completion network in the
paper).
</li>
</ol>
</div>
</div>
<div id="outline-container-sec-1-1-3" class="outline-4">
<h4 id="sec-1-1-3"><span class="section-number-4">1.1.3</span> <span class="label label-primary TODO">TODO</span> Mathematical Details</h4>
</div>
</div>


<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> Weakly supervised disentangling</h3>
<div class="outline-text-3" id="text-1-2">
<p>
This paper proposed a recurrent convolutional encoder-decoder network
with <b>action units</b> to model the process of pose manifold traversal,
consisting of four components:
</p>
<ol class="org-ol">
<li>a deep convolutional encoder,
</li>
<li>shared identity units,
</li>
<li>recurrent pose units with rotation action inputs, and
</li>
<li>a deep convolutional decoder
</li>
</ol>
</div>

<div id="outline-container-sec-1-2-1" class="outline-4">
<h4 id="sec-1-2-1"><span class="section-number-4">1.2.1</span> Main Contribution</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
The main contributions of this work are:
</p>
<ol class="org-ol">
<li>a new network was developed for learning to apply out-of-plane
rotations to human faces and 3D chair models.
</li>
<li>the learned model can generate realistic rotation trajectories with
a control signal supplied at each step by the user.
</li>
<li>despite only trained to synthesize images, this model learns
discriminative view-invariant features without using class labels.
This weakly-supervised disentangling is especially notable with
longer-term prediction.
</li>
</ol>
</div>
</div>
</div>
</div>
</div><div class="col-md-3"><nav id="table-of-contents">
<div id="text-table-of-contents" class="bs-docs-sidebar">
<ul class="nav">
<li><a href="#sec-1">1. 2017.6.29-2017.9.10</a>
<ul class="nav">
<li><a href="#sec-1-1">1.1. Transformation-Grouned Image Generation Network for Novel 3D View Synthesis</a></li>
<li><a href="#sec-1-2">1.2. Weakly supervised disentangling</a></li>
</ul>
</li>
</ul>
</div>
</nav>
</div></div></div>
<footer id="postamble" class="">
<div><p class="author">Author: Liangzu Peng</p>
<p class="email">Email: <a href="mailto:faithofplz@gmail.com">faithofplz@gmail.com</a></p>
<p class="date">Created: 2018-01-08 一 10:12</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 27.0.50 (<a href="http://orgmode.org">Org-mode</a> 9.1.8)</p>
</div>
</footer>
</body>
</html>
